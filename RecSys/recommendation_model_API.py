import os
import json
from typing import Dict, Any, List, Optional, Tuple
from openai import OpenAI
import httpx
from config import settings
from supabase import create_client
from sentence_transformers import CrossEncoder
import torch

<<<<<<< HEAD
# Global cache for products
PRODUCTS_CACHE = {}
=======
# Cross-Encoder ì„¤ì •
TOP_K = 3
CANDIDATE_POOL = 200
EMBED_MODEL = "text-embedding-3-small"
EMBED_DIM = 1536
CE_MODEL = "BAAI/bge-reranker-v2-m3"
KW_BONUS_ALPHA = 1.2
CUSTOMER_ID_COL = "user_id"
PRODUCT_VECTOR_FK_COL = "product_id"

# ë™ì˜ì–´ ë§¤í•‘
SKIN_TYPE_MAP = {
    "Sensitive": "ë¯¼ê°ì„±",
    "Dry": "ê±´ì„±",
    "Oily": "ì§€ì„±",
    "Combination": "ë³µí•©ì„±",
    "Neutral": "ì¤‘ì„±",
    "Normal": "ì¤‘ì„±",
}

CONCERN_MAP = {
    "Pores": "ëª¨ê³µ",
    "Sebum": "í”¼ì§€",
    "Acne": "ì—¬ë“œë¦„",
    "Redness": "í™ì¡°",
    "Dryness": "ê±´ì¡°",
    "Wrinkle": "ì£¼ë¦„",
    "Elasticity": "íƒ„ë ¥",
    "Dullness": "ì¹™ì¹™í•¨",
    "Anti-aging": "ì•ˆí‹°ì—ì´ì§•",
    "Antiaging": "ì•ˆí‹°ì—ì´ì§•",
    "Sensitive": "ë¯¼ê°",
    "Sensitivity": "ë¯¼ê°",
}

TONE_MAP = {
    "Cool_Summer": "ì¿¨í†¤ ì—¬ë¦„",
    "Cool_Winter": "ì¿¨í†¤ ê²¨ìš¸",
    "Warm_Spring": "ì›œí†¤ ë´„",
    "Warm_Autumn": "ì›œí†¤ ê°€ì„",
    "Neutral": "ë‰´íŠ¸ëŸ´",
}

# Cross-Encoder ìºì‹± (í•œ ë²ˆë§Œ ë¡œë“œ)
_cross_encoder_cache = None
>>>>>>> origin/main

client = OpenAI(api_key=settings.OPENAI_API_KEY)

def get_cross_encoder() -> CrossEncoder:
    """Cross-Encoderë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _cross_encoder_cache
    if _cross_encoder_cache is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"[CrossEncoder] loading: {CE_MODEL} on device={device}")
        _cross_encoder_cache = CrossEncoder(CE_MODEL, device=device)
    return _cross_encoder_cache


def normalize_list(v: Any) -> List[str]:
    """ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”"""
    if v is None:
        return []
    if isinstance(v, list):
        return [str(x).strip() for x in v if str(x).strip()]
    if isinstance(v, str):
        s = v.strip()
        if s.startswith("{") and s.endswith("}"):
            s = s[1:-1]
        return [x.strip().strip('"') for x in s.split(",") if x.strip()]
    return [str(v).strip()]


def with_kr(items: List[str], mapping: Dict[str, str]) -> List[str]:
    """ì˜ì–´ í‚¤ì›Œë“œì— í•œê¸€ ë§¤í•‘ ì¶”ê°€"""
    out = []
    for x in items:
        k = mapping.get(x)
        out.append(f"{x}({k})" if k else x)
    return out


def build_user_query_text(customer: Dict[str, Any]) -> str:
    """ìœ ì € ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±"""
    skin_types = with_kr(normalize_list(customer.get("skin_type")), SKIN_TYPE_MAP)
    concerns = with_kr(normalize_list(customer.get("skin_concerns")), CONCERN_MAP)
    keywords = normalize_list(customer.get("keywords"))
    tone = customer.get("preferred_tone")
    tone_kr = TONE_MAP.get(tone, tone) if tone else None

    lines = [
        "ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆ ì¶”ì²œ ì¿¼ë¦¬ (í‚¤ì›Œë“œ ìµœìš°ì„ )",
        "",
        "[ì¤‘ìš” í‚¤ì›Œë“œ TOP - ìµœìš°ì„  ë°˜ì˜]",
        f"- {', '.join(keywords)}" if keywords else "- (ì—†ìŒ)",
        "â€» ìœ„ í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” íš¨ëŠ¥/íŠ¹ì§•/ì œí’ˆ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì œí’ˆì„ ìµœìš°ì„ ìœ¼ë¡œ í‰ê°€í•œë‹¤.",
        "",
        "[í”¼ë¶€íƒ€ì…]",
        f"- {', '.join(skin_types)}" if skin_types else "- ì •ë³´ ì—†ìŒ",
        "",
        "[í”¼ë¶€ê³ ë¯¼]",
        f"- {', '.join(concerns)}" if concerns else "- ì •ë³´ ì—†ìŒ",
        "",
        "[ì¶”êµ¬ í†¤]",
        f"- {tone_kr}" if tone_kr else "- ì •ë³´ ì—†ìŒ",
        "",
        "[í‰ê°€ ê¸°ì¤€ ì¬ê°•ì¡°]",
        f"- í•µì‹¬ í‚¤ì›Œë“œ({', '.join(keywords)})ì™€ ì—°ê´€ì„±ì´ ë†’ì€ ì œí’ˆì„ ìš°ì„  ì¶”ì²œ" if keywords else "- í‚¤ì›Œë“œ ê¸°ë°˜ ìš°ì„  ì¶”ì²œ",
    ]
    return "\n".join(lines)


def embed_text(oa: OpenAI, text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    res = oa.embeddings.create(
        model=EMBED_MODEL,
        input=[text],
        encoding_format="float",
    )
    emb = res.data[0].embedding
    if len(emb) != EMBED_DIM:
        raise ValueError(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: got {len(emb)} expected {EMBED_DIM}")
    return emb


def truncate_for_ce(text: str, max_chars: int = 1800) -> str:
    """Cross-Encoder ì…ë ¥ ê¸¸ì´ ì œí•œ"""
    text = text or ""
    return text if len(text) <= max_chars else text[:max_chars]


def keyword_bonus(user_keywords: List[str], product_content: str) -> float:
    """í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤ ê³„ì‚° (0~1)"""
    kws = [k.strip() for k in (user_keywords or []) if k and str(k).strip()]
    if not kws:
        return 0.0

    text = (product_content or "").lower()
    keyword_line = ""
    for line in (product_content or "").splitlines():
        if "í‚¤ì›Œë“œ" in line:
            keyword_line = line.lower()
            break

    hit_any = 0
    hit_kwline = 0
    for kw in kws:
        k = kw.lower()
        if k in text:
            hit_any += 1
        if keyword_line and k in keyword_line:
            hit_kwline += 1

    score = (2.0 * hit_kwline + 1.0 * hit_any) / (3.0 * max(len(kws), 1))
    return float(min(1.0, max(0.0, score)))


async def fetch_products_from_supabase() -> Dict[str, str]:
    """
    Fetch products from Supabase and format them for the LLM.
    (Deprecated - ì´ì œ recommend_product_with_brands ì‚¬ìš©)
    """
<<<<<<< HEAD
    global PRODUCTS_CACHE
    if PRODUCTS_CACHE:
        return PRODUCTS_CACHE
=======
    return {}
>>>>>>> origin/main

    url = f"{settings.SUPABASE_URL}/rest/v1/products"
    headers = {
        "apikey": settings.SUPABASE_KEY,
        "Authorization": f"Bearer {settings.SUPABASE_KEY}",
    }

    try:
        async with httpx.AsyncClient() as http_client:
            response = await http_client.get(url, headers=headers)
            response.raise_for_status()
            products_data = response.json()

            # Format: "ID": "Name (Brand, Category, Description)"
            formatted_products = {}
            for p in products_data:
                # Adjust field names based on actual DB schema
                # Schema: id, product_code, brand, name, category_major, category_middle, category_small, 
                # price_original, price_final, discount_rate, review_score, review_count, features, analytics, keywords

                p_id = p.get("product_code") or str(p.get("id"))
                name = p.get("name")
                brand = p.get("brand", "")

                # Construct category string
                cats = [p.get("category_major"), p.get("category_middle"), p.get("category_small")]
                category = " > ".join([c for c in cats if c])

                # Construct description from keywords and features
                keywords = p.get("keywords", "")
                price = p.get("price_final")
                review_score = p.get("review_score")

                desc_parts = []
                if keywords:
                    desc_parts.append(f"Keywords: {keywords}")
                if price:
                    desc_parts.append(f"Price: {price}")
                if review_score:
                    desc_parts.append(f"Rating: {review_score}")

                desc = ", ".join(desc_parts)

                if p_id and name:
                    info = f"{name} (Brand: {brand}, Category: {category}, {desc})"
                    formatted_products[p_id] = info

            PRODUCTS_CACHE = formatted_products

            # Debug: Print first 3 products to verify format
            print("DEBUG: Sample products from DB:")
            for i, (pid, info) in enumerate(formatted_products.items()):
                if i >= 3: break
                print(f" - {pid}: {info}")

            return formatted_products

    except Exception as e:
        print(f"Failed to fetch products from Supabase: {e}")
        # Fallback to empty dict or hardcoded list if needed
        return {}

async def recommend_product_with_brands(
    user_id: str,
    user_data: Any,
    target_brands: List[str] = None,
    top_k: int = 1
) -> Optional[Dict[str, Any]]:
    """
    ìœ ì € IDì™€ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ Cross-Encoder ê¸°ë°˜ìœ¼ë¡œ ìµœê³ ì˜ ìƒí’ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤.
    
    Args:
        user_id: ì‚¬ìš©ì ID
        user_data: CustomerProfile ê°ì²´ (user_dataì—ì„œ ì¶”ì¶œí•œ ì •ë³´)
        target_brands: ì¶”ì²œí•  ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ë¸Œëœë“œ)
        top_k: ë°˜í™˜í•  ìƒí’ˆ ê°œìˆ˜ (ê¸°ë³¸ê°’: 1)
        
    Returns:
        ì¶”ì²œ ìƒí’ˆ ì •ë³´ dict ë˜ëŠ” None
    """
<<<<<<< HEAD
    # Fetch products dynamically
    products_db = await fetch_products_from_supabase()
    print(f"DEBUG: Fetched {len(products_db)} products from DB.")

    # If DB fetch fails or is empty, use a rich mock DB for testing
    if not products_db:
        print("DEBUG: Using mock DB")
        products_db = {
            "SW-SERUM-001": "Sulwhasoo Concentrated Ginseng Renewing Serum (Brand: Sulwhasoo, Category: Serum, Anti-aging, Dry skin)",
            "HR-CUSHION-02": "Hera Black Cushion (Brand: Hera, Category: Makeup, All skin types, Trendy)",
            "HR-FOUNDATION-01": "Hera Silky Stay Foundation (Brand: Hera, Category: Makeup, Long-lasting)",
            "IO-CREAM-003": "IOPE Stem III Cream (Brand: IOPE, Category: Cream, Anti-aging, Repair)",
            "LN-MASK-004": "Laneige Water Sleeping Mask (Brand: Laneige, Category: Mask, Hydration, Night care)",
            "ET-TONER-005": "Etude House SoonJung Toner (Brand: Etude, Category: Toner, Sensitive, Soothing)",
            "IN-CLAY-006": "Innisfree Volcanic Pore Clay Mask (Brand: Innisfree, Category: Mask, Pore care, Oily skin)"
        }

    # Filter by target_brand if provided
    target_brands = getattr(request_data, 'target_brand', None)
    if target_brands:
        filtered_products = {}
        for pid, info in products_db.items():
            # Check if ANY target brand is in the product info
            # Info format: "Name (Brand: BrandName, ...)"
            # We check if any brand in the list is present in the info string
            if any(brand.lower() in info.lower() for brand in target_brands):
                filtered_products[pid] = info

        if filtered_products:
            products_db = filtered_products
            print(f"Filtered by brands {target_brands}: {len(products_db)} products found.")
        else:
            print(f"No products found for brands {target_brands}. Using all products.")

    # Limit the number of products to avoid token limits (TPM 30k limit)
    MAX_PRODUCTS = 20
    if len(products_db) > MAX_PRODUCTS:
        print(f"DEBUG: Limiting products from {len(products_db)} to {MAX_PRODUCTS} (Randomly)")
        import random
        # Randomly sample items
        sampled_items = random.sample(list(products_db.items()), MAX_PRODUCTS)
        products_db = dict(sampled_items)

    case = request_data.case
    user_data = request_data.user_data

    system_prompt = f"""
    You are an expert beauty product recommendation AI.
    You must recommend ONE product from the following list:
    {json.dumps(products_db, indent=2)}
    
    Return the result in JSON format with the following keys:
    - product_id: The ID of the recommended product.
    - product_name: The exact name of the recommended product.
    - score: A confidence score between 0.0 and 1.0.
    - reason: A short explanation of why this product was recommended (in Korean).
    """

    user_prompt = ""

    if case == 1:
        # Case 1: No data (Cold start)
        user_prompt = "I have no information about this user. Recommend a generally popular best-seller product that works for most people."

    elif case == 2:
        # Case 2: History/Context only
        # Extract relevant history fields from user_data
        history_context = {
            "purchase_history": [item.dict() for item in user_data.purchase_history] if user_data else [],
            "shopping_behavior": user_data.shopping_behavior.dict() if user_data else {},
            "cart_items": [item.dict() for item in user_data.cart_items] if user_data else [],
            "recently_viewed_items": [item.dict() for item in user_data.recently_viewed_items] if user_data else [],
            "last_purchase": user_data.last_purchase.dict() if user_data and user_data.last_purchase else None
        }

        user_prompt = f"""
        Recommend a product based on the user's past history and behavior context:
        {json.dumps(history_context, indent=2, default=str)}
        
        Key factors to consider:
        - Recent purchases and repurchase cycles
        - Shopping behavior (price sensitivity, cart abandonment)
        - Currently in cart or recently viewed items
        """

    elif case == 3:
        # Case 3: Profile only
        if not user_data:
             user_prompt = "User profile is missing. Recommend a popular product."
        else:
            user_prompt = f"""
            Recommend a product based on the user's beauty profile:
            Name: {user_data.name}
            Age Group: {user_data.age_group}
            Gender: {user_data.gender}
            Membership: {user_data.membership_level}
            Skin Type: {', '.join(user_data.skin_type)}
            Skin Concerns: {', '.join(user_data.skin_concerns)}
            Preferred Tone: {user_data.preferred_tone}
            Keywords: {', '.join(user_data.keywords)}
            """

    elif case == 4:
        # Case 4: Both Profile and History
        if not user_data:
             user_prompt = "User data is missing. Recommend a popular product."
        else:
            user_prompt = f"""
            Recommend a product based on both the user's detailed profile and behavioral context.
            
            [User Profile]
            Name: {user_data.name}
            Age Group: {user_data.age_group}
            Gender: {user_data.gender}
            Membership: {user_data.membership_level}
            Skin Type: {', '.join(user_data.skin_type)}
            Skin Concerns: {', '.join(user_data.skin_concerns)}
            Preferred Tone: {user_data.preferred_tone}
            Keywords: {', '.join(user_data.keywords)}
            
            [User History & Context]
            {json.dumps(user_data.dict(exclude={'name', 'age_group', 'gender', 'membership_level', 'skin_type', 'skin_concerns', 'preferred_tone', 'keywords'}), indent=2, default=str)}
            
            Comprehensive Analysis Instructions:
            1. Check 'cart_items' and 'recently_viewed_items' for immediate interest.
            2. Check 'repurchase_cycle_alert' to see if they need a refill.
            3. Match 'skin_concerns' and 'keywords' with product benefits.
            4. Consider 'price_sensitivity' and 'average_order_value'.
            5. If they are a 'VVIP', recommend premium lines.
            """

    else:
        # Fallback
        user_prompt = "Recommend a popular product."

    try:
        response = client.chat.completions.create(
            model="gpt-4o", # Or gpt-3.5-turbo
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.7
        )

        content = response.choices[0].message.content
        result = json.loads(content)

        # Validate product_id
        if result.get("product_id") not in products_db:
            # Fallback if LLM hallucinates an ID
            # Use the first available product ID from the DB
            fallback_id = next(iter(products_db)) if products_db else "HR-FOUNDATION-01"
            result["product_id"] = fallback_id
            # Try to extract name from DB value or use default
            db_val = products_db.get(fallback_id, "Hera Silky Stay Foundation")
            # DB value format: "Name (Brand: ...)"
            result["product_name"] = db_val.split(" (")[0] if " (" in db_val else db_val
            result["reason"] = "ê¸°ë³¸ ì¶”ì²œ ìƒí’ˆì…ë‹ˆë‹¤. (LLM ID ì˜¤ë¥˜)"

        return result

    except Exception as e:
        print(f"LLM Error: {e}")
        # Fallback in case of error
        return {
            "product_id": "HR-FOUNDATION-01",
            "product_name": "Hera Silky Stay Foundation",
            "score": 0.5,
            "reason": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì¶”ì²œì…ë‹ˆë‹¤."
        }
=======
    try:
        # Supabase ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        sb = create_client(settings.SUPABASE_URL, settings.SUPABASE_KEY)
        oa = OpenAI(api_key=settings.OPENAI_API_KEY)
        ce = get_cross_encoder()
        
        # 1) ê³ ê° ì •ë³´ ì¡°íšŒ
        customer_resp = (
            sb.table("customers")
            .select("user_id, skin_type, skin_concerns, keywords, preferred_tone")
            .eq(CUSTOMER_ID_COL, user_id)
            .limit(1)
            .execute()
        )
        
        if not customer_resp.data:
            print(f"[WARN] customersì—ì„œ {CUSTOMER_ID_COL}={user_id}ë¥¼ ì°¾ì§€ ëª»í•¨")
            return None
        
        customer = customer_resp.data[0]
        user_keywords = normalize_list(customer.get("keywords"))
        
        # 2) ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
        query_text = build_user_query_text(customer)
        
        # 3) ì„ë² ë”© ìƒì„±
        query_emb = embed_text(oa, query_text)
        
        # 4) ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í›„ë³´ í’€)
        rpc_payload = {
            "filter": {},
            "match_count": CANDIDATE_POOL,
            "query_embedding": query_emb,
        }
        match_resp = sb.rpc("match_products", rpc_payload).execute()
        matches = match_resp.data or []
        
        if not matches:
            print("[WARN] ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        matches.sort(key=lambda m: float(m.get("similarity", 0.0)), reverse=True)
        candidate_ids = [m["product_id"] for m in matches]
        sim_map = {m["product_id"]: float(m["similarity"]) for m in matches}
        
        # 5) products ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë¸Œëœë“œ í•„í„°ë§ ì ìš©)
        query = (
            sb.table("products")
            .select("id, brand, name, category_major, category_middle, category_small, price_final, discount_rate, review_score, review_count")
            .in_("id", candidate_ids)
        )
        
        if target_brands and len(target_brands) > 0:
            query = query.in_("brand", target_brands)
            print(f"  ğŸ·ï¸ ë¸Œëœë“œ í•„í„°ë§ ì ìš©: {target_brands}")
        
        products_resp = query.execute()
        products = products_resp.data or []
        
        if not products:
            if target_brands:
                print(f"[WARN] ì§€ì •ëœ ë¸Œëœë“œ({target_brands})ì—ì„œ ìƒí’ˆì„ ì°¾ì§€ ëª»í•¨")
            else:
                print("[WARN] ìƒí’ˆì„ ì°¾ì§€ ëª»í•¨")
            return None
        
        prod_map = {p["id"]: p for p in products}
        filtered_ids = list(prod_map.keys())
        
        # 6) products_vector content ê°€ì ¸ì˜¤ê¸°
        pv_resp = (
            sb.table("products_vector")
            .select(f"{PRODUCT_VECTOR_FK_COL}, content")
            .in_(PRODUCT_VECTOR_FK_COL, filtered_ids)
            .execute()
        )
        pv_rows = pv_resp.data or []
        pv_map = {r[PRODUCT_VECTOR_FK_COL]: r.get("content") for r in pv_rows}
        
        # 7) Cross-Encoder rerank + keyword bonus
        pairs: List[Tuple[str, str]] = []
        valid_ids: List[int] = []
        
        for pid in filtered_ids:
            content = pv_map.get(pid)
            if not content:
                continue
            valid_ids.append(pid)
            pairs.append((truncate_for_ce(query_text), truncate_for_ce(content)))
        
        if not pairs:
            print("[WARN] ë¸Œëœë“œ í•„í„°ë§ í›„ products_vector.contentê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None
        
        ce_scores = ce.predict(pairs)
        
        reranked = []
        for pid, ce_score in zip(valid_ids, ce_scores):
            content = pv_map.get(pid, "")
            kwb = keyword_bonus(user_keywords, content)
            final_score = float(ce_score) + KW_BONUS_ALPHA * kwb
            p = prod_map.get(pid)
            
            reranked.append({
                "product_id": str(pid),
                "brand": p.get("brand"),
                "name": p.get("name"),
                "category_major": p.get("category_major"),
                "category_middle": p.get("category_middle"),
                "category_small": p.get("category_small"),
                "price_final": p.get("price_final"),
                "discount_rate": p.get("discount_rate"),
                "review_score": p.get("review_score"),
                "review_count": p.get("review_count"),
                "ce_score": float(ce_score),
                "kw_bonus": float(kwb),
                "final_score": float(final_score),
                "similarity": float(sim_map.get(pid, 0.0)),
            })
        
        reranked.sort(key=lambda r: r["final_score"], reverse=True)
        
        # 8) top_k ê°œìˆ˜ë§Œí¼ ë°˜í™˜
        if top_k == 1:
            return reranked[0] if reranked else None
        else:
            return reranked[:top_k]
            
    except Exception as e:
        print(f"âŒ ìƒí’ˆ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


async def get_recommendation(request_data: Any) -> Dict[str, Any]:
    """
    Get recommendation using Cross-Encoder based system.
    """
    user_id = request_data.user_id
    intention = getattr(request_data, 'intention', None)
    user_data = request_data.user_data
    target_brands = getattr(request_data, 'target_brand', None)
    
    print(f"\nğŸ¯ ì¶”ì²œ ìš”ì²­ ìˆ˜ì‹ :")
    print(f"  - User ID: {user_id}")
    print(f"  - Intention: {intention}")
    print(f"  - Target Brands: {target_brands}")
    
    # Cross-Encoder ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ í˜¸ì¶œ
    recommendation = await recommend_product_with_brands(
        user_id=user_id,
        user_data=user_data,
        target_brands=target_brands if target_brands else [],
        top_k=1
    )
    
    if recommendation:
        print(f"  âœ… ìƒí’ˆ ì¶”ì²œ ì„±ê³µ: {recommendation['name']} (ID: {recommendation['product_id']})")
        print(f"  ğŸ“Š Score: ce={recommendation['ce_score']:.4f}, kw_bonus={recommendation['kw_bonus']:.3f}, final={recommendation['final_score']:.4f}")
        
        result = {
            "product_id": recommendation['product_id'],
            "product_name": recommendation['name'],
            "score": recommendation['final_score'],
            "reason": f"Cross-Encoder ì ìˆ˜: {recommendation['ce_score']:.4f}, í‚¤ì›Œë“œ ë§¤ì¹­: {recommendation['kw_bonus']:.3f}",
            "product_data": {
                "product_id": recommendation['product_id'],
                "brand": recommendation['brand'],
                "name": recommendation['name'],
                "category": {
                    "major": recommendation['category_major'],
                    "middle": recommendation['category_middle'],
                    "small": recommendation['category_small'],
                },
                "price": {
                    "original_price": recommendation['price_final'],
                    "discounted_price": recommendation['price_final'],
                    "discount_rate": recommendation['discount_rate'],
                },
                "review": {
                    "score": recommendation['review_score'],
                    "count": recommendation['review_count'],
                    "top_keywords": [],
                },
                "description_short": f"{recommendation['name']} - {recommendation['brand']}",
            }
        }
        return result
    
    # ì¶”ì²œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
    print("  âš ï¸ ì¶”ì²œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜")
    return {
        "product_id": "UNKNOWN",
        "product_name": "ì¶”ì²œ ì‹¤íŒ¨",
        "score": 0.0,
        "reason": "ìƒí’ˆ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
    }


>>>>>>> origin/main
