import os
import json
from typing import Dict, Any, List, Optional, Tuple
from openai import OpenAI
import httpx
from config import settings
from sentence_transformers import CrossEncoder
import torch
from datetime import datetime

# Cross-Encoder ì„¤ì •
TOP_K = 3
CANDIDATE_POOL = 30
EMBED_MODEL = "text-embedding-3-small"
EMBED_DIM = 1536
CE_MODEL = "BAAI/bge-reranker-v2-m3"
KW_BONUS_ALPHA = 1.2
CUSTOMER_ID_COL = "user_id"
PRODUCT_VECTOR_FK_COL = "product_id"

# ë™ì˜ì–´ ë§¤í•‘
SKIN_TYPE_MAP = {
    "Sensitive": "ë¯¼ê°ì„±",
    "Dry": "ê±´ì„±",
    "Oily": "ì§€ì„±",
    "Combination": "ë³µí•©ì„±",
    "Neutral": "ì¤‘ì„±",
    "Normal": "ì¤‘ì„±",
}

CONCERN_MAP = {
    "Pores": "ëª¨ê³µ",
    "Sebum": "í”¼ì§€",
    "Acne": "ì—¬ë“œë¦„",
    "Redness": "í™ì¡°",
    "Dryness": "ê±´ì¡°",
    "Wrinkle": "ì£¼ë¦„",
    "Elasticity": "íƒ„ë ¥",
    "Dullness": "ì¹™ì¹™í•¨",
    "Anti-aging": "ì•ˆí‹°ì—ì´ì§•",
    "Antiaging": "ì•ˆí‹°ì—ì´ì§•",
    "Sensitive": "ë¯¼ê°",
    "Sensitivity": "ë¯¼ê°",
}

TONE_MAP = {
    "Cool_Summer": "ì¿¨í†¤ ì—¬ë¦„",
    "Cool_Winter": "ì¿¨í†¤ ê²¨ìš¸",
    "Warm_Spring": "ì›œí†¤ ë´„",
    "Warm_Autumn": "ì›œí†¤ ê°€ì„",
    "Neutral": "ë‰´íŠ¸ëŸ´",
}

# ì˜ì–´ í‚¤ì›Œë“œ -> í•œê¸€ ë™ì˜ì–´ ë§¤í•‘ (í‚¤ì›Œë“œ ë§¤ì¹­ë¥  ê°œì„ )
KEYWORD_TRANSLATION = {
    # íš¨ëŠ¥ í‚¤ì›Œë“œ
    "antiaging": ["ì•ˆí‹°ì—ì´ì§•", "ì•ˆí‹°", "ì£¼ë¦„", "ì£¼ë¦„ê°œì„ ", "ì£¼ë¦„ì¼€ì–´", "íƒ„ë ¥", "íƒ„ë ¥ì¼€ì–´", "íƒ„ë ¥ê°œì„ ", "ì–´ë ¤ë³´ì´ëŠ”", "í•­ì‚°í™”", "ë¦¬í”„íŒ…", "ë…¸í™”", "ì•ˆí‹°ì—ì´ì§€", "ê°œì„ íš¨ê³¼"],
    "anti_aging": ["ì•ˆí‹°ì—ì´ì§•", "ì•ˆí‹°", "ì£¼ë¦„", "ì£¼ë¦„ê°œì„ ", "ì£¼ë¦„ì¼€ì–´", "íƒ„ë ¥", "íƒ„ë ¥ì¼€ì–´", "íƒ„ë ¥ê°œì„ ", "ì–´ë ¤ë³´ì´ëŠ”", "í•­ì‚°í™”", "ë¦¬í”„íŒ…", "ë…¸í™”", "ê°œì„ íš¨ê³¼"],
    "firming": ["íƒ„ë ¥", "íƒ„ë ¥ì¼€ì–´", "íƒ„ë ¥ê°œì„ ", "ë¦¬í”„íŒ…", "í¼ë°", "íƒ„íƒ„", "elasticity", "firmness", "ê¸´ì¥", "í”¼ë¶€íƒ„ë ¥"],
    "whitening": ["í™”ì´íŠ¸ë‹", "ë¯¸ë°±", "ë¸Œë¼ì´íŠ¸ë‹", "í†¤ì—…", "brightening", "ë¸Œë¼ì´íŠ¸", "í™”ì‚¬", "í”¼ë¶€í†¤", "í†¤ê°œì„ "],
    "brightening": ["ë¸Œë¼ì´íŠ¸ë‹", "í™”ì´íŠ¸ë‹", "ë¯¸ë°±", "í†¤ì—…", "í™”ì‚¬", "í”¼ë¶€í†¤", "ë°ì€"],
    "nutrition": ["ì˜ì–‘", "nutrition", "ì˜ì–‘ê°", "ì˜ì–‘ê³µê¸‰", "ì˜ì–‘í¬ë¦¼", "nourishing"],
    "moisturizing": ["ë³´ìŠµ", "ë³´ìŠµê°", "ë³´ìŠµë ¥", "ìˆ˜ë¶„", "ìˆ˜ë¶„ê°", "ìˆ˜ë¶„ê³µê¸‰", "ì´‰ì´‰", "ì´‰ì´‰í•œ", "hydrating", "í•˜ì´ë“œë ˆì´íŒ…", "moisturize"],
    "hydrating": ["ìˆ˜ë¶„", "ìˆ˜ë¶„ê°", "ìˆ˜ë¶„ê³µê¸‰", "ë³´ìŠµ", "ë³´ìŠµê°", "ì´‰ì´‰", "ì´‰ì´‰í•œ"],
    "nourishing": ["ì˜ì–‘", "ì˜ì–‘ê°", "ì˜ì–‘ê³µê¸‰", "ì˜ì–‘í¬ë¦¼"],
    "exfoliating": ["ê°ì§ˆ", "ê°ì§ˆì œê±°", "ê°ì§ˆì¼€ì–´", "ê°ì§ˆê´€ë¦¬", "peeling", "í•„ë§"],
    "peeling": ["í•„ë§", "ê°ì§ˆì œê±°", "ê°ì§ˆì¼€ì–´", "ê°ì§ˆ"],
    "soothing": ["ì§„ì •", "ìˆ˜ë”©", "í¸ì•ˆ", "í¸ì•ˆí•œ", "calm", "calming", "ì§„ì •íš¨ê³¼"],
    "calming": ["ì§„ì •", "ìˆ˜ë”©", "í¸ì•ˆ", "í¸ì•ˆí•œ", "calm"],
    
    # í”¼ë¶€íƒ€ì…/ê³ ë¯¼
    "sensitive": ["ë¯¼ê°", "ë¯¼ê°ì„±", "ìˆœí•œ", "ìê·¹ì—†ëŠ”", "gentle", "ì„¼ì‹œí‹°ë¸Œ", "ë¯¼ê°ì„±í”¼ë¶€", "ë¯¼ê°í”¼ë¶€"],
    "acne": ["ì—¬ë“œë¦„", "íŠ¸ëŸ¬ë¸”", "ì•„í¬ë„¤", "í”¼ì§€", "ëª¨ê³µ", "trouble"],
    "pore": ["ëª¨ê³µ", "pore", "í”¼ì§€", "ë¸”ë™í—¤ë“œ", "ëª¨ê³µì¼€ì–´"],
    "sebum": ["í”¼ì§€", "ìœ ë¶„", "sebum", "ì˜¤ì¼", "ìœ ë¶„ì¡°ì ˆ"],
    "dry": ["ê±´ì¡°", "ê±´ì„±", "ìˆ˜ë¶„ë¶€ì¡±", "ê±´ì¡°í•¨"],
    "oily": ["ì§€ì„±", "ìœ ë¶„", "í”¼ì§€", "ì˜¤ì¼ë¦¬"],
    
    # í’ˆì§ˆ/ë“±ê¸‰
    "premium": ["í”„ë¦¬ë¯¸ì—„", "ê³ ê¸‰", "ê³ ê¸‰ìŠ¤ëŸ¬ìš´", "ëŸ­ì…”ë¦¬", "ëª…í’ˆ", "ìµœê³ ê¸‰"],
    "luxury": ["ëŸ­ì…”ë¦¬", "ê³ ê¸‰", "í”„ë¦¬ë¯¸ì—„", "ëª…í’ˆ"],
    "glow": ["ê´‘ì±„", "ìœ¤ê¸°", "ë¹›ë‚˜ëŠ”", "ê¸€ë¡œìš°", "radiance", "ë˜ë””ì–¸ìŠ¤", "ë¹›", "ìƒê¸°", "í”¼ë¶€í†¤", "í†¤", "í†¤ê°œì„ "],
    "radiance": ["ë˜ë””ì–¸ìŠ¤", "ê´‘ì±„", "ìœ¤ê¸°", "ë¹›ë‚˜ëŠ”", "ìƒê¸°"],
    "dermatologisttested": ["í”¼ë¶€ê³¼", "ì„ìƒ", "í…ŒìŠ¤íŠ¸", "dermatologist", "í”¼ë¶€ê³¼í…ŒìŠ¤íŠ¸", "ì „ë¬¸ê°€"],
    "dermatologist_tested": ["í”¼ë¶€ê³¼", "ì„ìƒ", "í…ŒìŠ¤íŠ¸", "ì „ë¬¸ê°€", "í”¼ë¶€ê³¼í…ŒìŠ¤íŠ¸"],
    
    # í…ìŠ¤ì²˜/ì‚¬ìš©ê°
    "lightweight": ["ê°€ë²¼ìš´", "ê°€ë²¼ìš´ì‚¬ìš©ê°", "ê°€ë²¼ìš´í…ìŠ¤ì²˜", "ê°€ë²¼ìš´ì œí˜•", "light"],
    "light": ["ê°€ë²¼ìš´", "ê°€ë³ê³ ", "ê°€ë²¼ìš´ì‚¬ìš©ê°"],
    "soft": ["ë¶€ë“œëŸ¬ìš´", "soft", "ì†Œí”„íŠ¸", "ë¶€ë“œëŸ½ê²Œ"],
    "gentle": ["ìˆœí•œ", "ë¶€ë“œëŸ¬ìš´", "ìê·¹ì—†ëŠ”", "ì  í‹€"],
    "rich": ["í’ë¶€í•œ", "ë†ì¶•", "ì§„í•œ", "ë¦¬ì¹˜"],
    "creamy": ["í¬ë¦¬ë¯¸í•œ", "ë¶€ë“œëŸ¬ìš´", "í¬ë¦¼ê°™ì€", "í¬ë¦¼"],
    "absorption": ["í¡ìˆ˜", "í¡ìˆ˜ë ¥", "ìŠ¤ë©°ë“¦", "ë¹ ë¥¸í¡ìˆ˜"],
    "nonsticky": ["ëˆì ì„ì—†ëŠ”", "ì‚°ëœ»í•œ", "ê°€ë²¼ìš´"],
    "nondrying": ["ê±´ì¡°í•˜ì§€ì•Šì€", "ì´‰ì´‰í•œ", "ë³´ìŠµ"],
    
    # ê°€ê²©/ê°€ì„±ë¹„
    "affordable": ["ê°€ì„±ë¹„", "ê°€ê²©ì €ë ´í•œ", "í•©ë¦¬ì ", "ê°€ê²©ëŒ€ë¹„", "ì €ë ´"],
    "valueformoney": ["ê°€ì„±ë¹„", "ê°€ê²©ëŒ€ë¹„", "ê°€ì„±ë¹„ì¢‹ì€"],
    "value_for_money": ["ê°€ì„±ë¹„", "ê°€ê²©ëŒ€ë¹„", "í•©ë¦¬ì "],
}

# ë‚ ì”¨/ì‹œì¦Œë³„ ì œí’ˆ í‚¤ì›Œë“œ ë§¤í•‘
WEATHER_KEYWORDS = {
    "spring": [
        "ë´„", "ë¯¸ì„¸ë¨¼ì§€", "í™©ì‚¬", "ê½ƒê°€ë£¨", "ì•ŒëŸ¬ì§€", "ì•Œë ˆë¥´ê¸°", "ì§„ì •", "ë³´í˜¸", "ë³´í˜¸ë§‰", 
        "ë°°ë¦¬ì–´", "í´ë Œì§•", "ì„¸ì•ˆ", "ë”¥í´ë Œì§•", "ë¯¼ê°", "ë¯¼ê°ì„±", "ìê·¹ì™„í™”", "ìˆœí•œ", 
        "ì €ìê·¹", "í•­ì‚°í™”", "ë¹„íƒ€ë¯¼C", "ì§„ì •íš¨ê³¼", "í”¼ë¶€ì§„ì •", "í”¼ë¶€ë³´í˜¸"
    ],
    "summer": [
        "ì—¬ë¦„", "í­ì—¼", "ìì™¸ì„ ", "ì¥ë§ˆ", "ìŠµë„", "UV", "SPF", "PA", "ì„ í¬ë¦¼", "ì¬", 
        "ì„ ì¼€ì–´", "ì¿¨ë§", "ì‹œì›í•œ", "ì‚°ëœ»í•œ", "ê°€ë²¼ìš´", "ë•€", "í”¼ì§€", "ëª¨ê³µ", "ìœ ë¶„", 
        "ì§€ì„±", "ìˆ˜ë¶„", "ì ¤", "ì—ì„¼ìŠ¤", "ìì™¸ì„ ì°¨ë‹¨", "ìœ ë¶„ì¡°ì ˆ", "ëª¨ê³µì¼€ì–´", "í”¼ì§€ì¡°ì ˆ", 
        "ì²­ëŸ‰", "ì²­ëŸ‰ê°", "ê°€ë²¼ìš´ì œí˜•", "ì‚°ëœ»í•œë°œë¦¼ì„±"
    ],
    "fall": [
        "ê°€ì„", "í™˜ì ˆê¸°", "ì¼êµì°¨", "ê±´ì¡°", "ê±´ì¡°í•œ", "ë³´ìŠµ", "ìˆ˜ë¶„", "ì§„ì •", "ë°¸ëŸ°ìŠ¤", 
        "ì¥ë²½", "ë°°ë¦¬ì–´", "íšŒë³µ", "ë¦¬í˜ì–´", "ì˜ì–‘", "ì¼€ì–´", "í”¼ë¶€ì¥ë²½", "ì„¸ë¼ë§ˆì´ë“œ", 
        "íˆì•Œë£¨ë¡ ì‚°", "í¬ë¦¼", "ë³´ìŠµê°", "íƒ„ë ¥", "ì´‰ì´‰í•œ", "ë¶€ë“œëŸ¬ìš´", "ì˜ì–‘ê³µê¸‰", 
        "ì¥ë²½ë¦¬í˜ì–´", "í”¼ë¶€ë°€ë„", "ë°€ë„"
    ],
    "winter": [
        "ê²¨ìš¸", "í•œíŒŒ", "ê±´ì¡°", "ê·¹ê±´ì¡°", "ë³´ìŠµ", "ê³ ë³´ìŠµ", "ìˆ˜ë¶„", "í¬ë¦¼", "ì˜¤ì¼", "ë°¤", 
        "ë†ì¶•", "ë¦¬ì¹˜", "ì˜ì–‘", "ì˜ì–‘í¬ë¦¼", "ë¦¬í”„íŒ…", "íƒ„ë ¥", "ë°€ì°©", "í”¼ë¶€ì¥ë²½", 
        "ì„¸ë¼ë§ˆì´ë“œ", "ì´‰ì´‰í•œë³´ìŠµê°", "ë¶€ë“œëŸ¬ìš´ë°œë¦¼ì„±", "ì¥ë²½ë¦¬í˜ì–´", "í”¼ë¶€ë°€ë„", "ë°€ë„"
    ]
}

# ê³„ì ˆë³„ í•µì‹¬ í‚¤ì›Œë“œ (ì¶”ê°€ ê°€ì¤‘ì¹˜ 2ë°° ì ìš©)
WEATHER_PRIORITY_KEYWORDS = {
    "spring": [
        # ë¯¸ì„¸ë¨¼ì§€/í™©ì‚¬ ëŒ€ì‘
        "ì§„ì •", "ë¯¼ê°", "ìˆœí•œ", "ì €ìê·¹", "ë³´í˜¸", "ë°°ë¦¬ì–´", "í”¼ë¶€ë³´í˜¸",
        "í´ë Œì§•", "ë”¥í´ë Œì§•", "ì„¸ì•ˆ",
        "ì•ŒëŸ¬ì§€", "ì•Œë ˆë¥´ê¸°", "ìê·¹ì™„í™”", "ì§„ì •íš¨ê³¼", "í”¼ë¶€ì§„ì •"
    ],
    "summer": [
        # ë•€/í”¼ì§€ ê´€ë¦¬ + ìì™¸ì„  ì°¨ë‹¨
        "ì‚°ëœ»", "ì‚°ëœ»í•œ", "ê°€ë²¼ìš´", "ëˆì ì„ì—†ëŠ”", "ë…¼ìŠ¤í‹°í‚¤", "ì¿¨ë§", "ì‹œì›í•œ",
        "SPF", "PA", "ìì™¸ì„ ", "ìì™¸ì„ ì°¨ë‹¨", "ì„ í¬ë¦¼", "ì„ ì¼€ì–´", "UV",
        "í”¼ì§€", "í”¼ì§€ì¡°ì ˆ", "ëª¨ê³µ", "ëª¨ê³µì¼€ì–´", "ìœ ë¶„ì¡°ì ˆ", "ì§€ì„±",
        "ì ¤", "ì²­ëŸ‰", "ì²­ëŸ‰ê°", "ê°€ë²¼ìš´ì œí˜•", "ì‚°ëœ»í•œë°œë¦¼ì„±"
    ],
    "fall": [
        # í™˜ì ˆê¸° ê±´ì¡° + í”¼ë¶€ì¥ë²½
        "ë³´ìŠµ", "ìˆ˜ë¶„", "ì´‰ì´‰", "ì´‰ì´‰í•œ", "ê±´ì¡°",
        "ì¥ë²½", "ë°°ë¦¬ì–´", "í”¼ë¶€ì¥ë²½", "ì¥ë²½ë¦¬í˜ì–´", "íšŒë³µ", "ë¦¬í˜ì–´",
        "ì§„ì •", "ë°¸ëŸ°ìŠ¤", "ì˜ì–‘", "ì˜ì–‘ê³µê¸‰",
        "ì„¸ë¼ë§ˆì´ë“œ", "íˆì•Œë£¨ë¡ ì‚°"
    ],
    "winter": [
        # ê·¹ê±´ì¡° ëŒ€ì‘ + ê³ ë³´ìŠµ
        "ë³´ìŠµ", "ê³ ë³´ìŠµ", "ìˆ˜ë¶„", "ê·¹ê±´ì¡°", "ê±´ì¡°",
        "í¬ë¦¼", "ë¦¬ì¹˜", "ë†ì¶•", "ë°€ì°©", "ì˜¤ì¼", "ë°¤",
        "ì˜ì–‘", "ì˜ì–‘í¬ë¦¼", "ì˜ì–‘ê³µê¸‰",
        "ì´‰ì´‰í•œë³´ìŠµê°", "ë¶€ë“œëŸ¬ìš´ë°œë¦¼ì„±",
        "ì„¸ë¼ë§ˆì´ë“œ", "í”¼ë¶€ì¥ë²½", "ì¥ë²½ë¦¬í˜ì–´"
    ]
}

# Cross-Encoder ìºì‹± (í•œ ë²ˆë§Œ ë¡œë“œ)
_cross_encoder_cache = None

client = OpenAI(api_key=settings.OPENAI_API_KEY)

def get_cross_encoder() -> CrossEncoder:
    """Cross-Encoderë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _cross_encoder_cache
    if _cross_encoder_cache is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"[CrossEncoder] loading: {CE_MODEL} on device={device}")
        _cross_encoder_cache = CrossEncoder(CE_MODEL, device=device)
    return _cross_encoder_cache


def normalize_list(v: Any) -> List[str]:
    """ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”"""
    if v is None:
        return []
    if isinstance(v, list):
        return [str(x).strip() for x in v if str(x).strip()]
    if isinstance(v, str):
        s = v.strip()
        if s.startswith("{") and s.endswith("}"):
            s = s[1:-1]
        return [x.strip().strip('"') for x in s.split(",") if x.strip()]
    return [str(v).strip()]


def with_kr(items: List[str], mapping: Dict[str, str]) -> List[str]:
    """ì˜ì–´ í‚¤ì›Œë“œì— í•œê¸€ ë§¤í•‘ ì¶”ê°€"""
    out = []
    for x in items:
        k = mapping.get(x)
        out.append(f"{x}({k})" if k else x)
    return out


def build_user_query_text(customer: Dict[str, Any]) -> str:
    """ìœ ì € ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±"""
    skin_types = with_kr(normalize_list(customer.get("skin_type")), SKIN_TYPE_MAP)
    concerns = with_kr(normalize_list(customer.get("skin_concerns")), CONCERN_MAP)
    keywords = normalize_list(customer.get("keywords"))
    
    # preferred_toneì´ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ (DB ìŠ¤í‚¤ë§ˆ ì°¨ì´)
    tone = customer.get("preferred_tone")
    if isinstance(tone, list):
        tone = tone[0] if tone else None
    
    tone_kr = TONE_MAP.get(tone, tone) if tone else None

    lines = [
        "ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆ ì¶”ì²œ ì¿¼ë¦¬ (í‚¤ì›Œë“œ ìµœìš°ì„ )",
        "",
        "[ì¤‘ìš” í‚¤ì›Œë“œ TOP - ìµœìš°ì„  ë°˜ì˜]",
        f"- {', '.join(keywords)}" if keywords else "- (ì—†ìŒ)",
        "â€» ìœ„ í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” íš¨ëŠ¥/íŠ¹ì§•/ì œí’ˆ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì œí’ˆì„ ìµœìš°ì„ ìœ¼ë¡œ í‰ê°€í•œë‹¤.",
        "",
        "[í”¼ë¶€íƒ€ì…]",
        f"- {', '.join(skin_types)}" if skin_types else "- ì •ë³´ ì—†ìŒ",
        "",
        "[í”¼ë¶€ê³ ë¯¼]",
        f"- {', '.join(concerns)}" if concerns else "- ì •ë³´ ì—†ìŒ",
        "",
        "[ì¶”êµ¬ í†¤]",
        f"- {tone_kr}" if tone_kr else "- ì •ë³´ ì—†ìŒ",
        "",
        "[í‰ê°€ ê¸°ì¤€ ì¬ê°•ì¡°]",
        f"- í•µì‹¬ í‚¤ì›Œë“œ({', '.join(keywords)})ì™€ ì—°ê´€ì„±ì´ ë†’ì€ ì œí’ˆì„ ìš°ì„  ì¶”ì²œ" if keywords else "- í‚¤ì›Œë“œ ê¸°ë°˜ ìš°ì„  ì¶”ì²œ",
    ]
    return "\n".join(lines)


def embed_text(oa: OpenAI, text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    res = oa.embeddings.create(
        model=EMBED_MODEL,
        input=[text],
        encoding_format="float",
    )
    emb = res.data[0].embedding
    if len(emb) != EMBED_DIM:
        raise ValueError(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: got {len(emb)} expected {EMBED_DIM}")
    return emb


def truncate_for_ce(text: str, max_chars: int = 1800) -> str:
    """Cross-Encoder ì…ë ¥ ê¸¸ì´ ì œí•œ"""
    text = text or ""
    return text if len(text) <= max_chars else text[:max_chars]


def expand_keywords(keywords: List[str]) -> List[str]:
    """ì˜ì–´ í‚¤ì›Œë“œë¥¼ í•œê¸€ ë™ì˜ì–´ë¡œ í™•ì¥í•˜ì—¬ ë§¤ì¹­ë¥  í–¥ìƒ"""
    expanded = []
    for kw in keywords:
        # ì›ë³¸ í‚¤ì›Œë“œ ì¶”ê°€
        expanded.append(kw)
        
        # ì •ê·œí™”: ì†Œë¬¸ì ë³€í™˜, ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
        normalized = kw.lower().replace("_", "").replace("-", "").replace(" ", "")
        
        # ë§¤í•‘ëœ í•œê¸€ ë™ì˜ì–´ ì¶”ê°€
        if normalized in KEYWORD_TRANSLATION:
            expanded.extend(KEYWORD_TRANSLATION[normalized])
    
    return expanded


def get_current_season() -> str:
    """í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì¦Œ ë°˜í™˜"""
    month = datetime.now().month
    if month in [3, 4, 5]:
        return "spring"
    elif month in [6, 7, 8]:
        return "summer"
    elif month in [9, 10, 11]:
        return "fall"
    else:  # 12, 1, 2
        return "winter"


def keyword_bonus(
    user_keywords: List[str], 
    product_content: str, 
    product_keywords: List[str], 
    skin_concerns: List[str] = None,
    weather_keywords: List[str] = None,
    current_season: str = None
) -> Tuple[float, Dict[str, Any]]:
    """í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤ ê³„ì‚° (0~1) - ë‹¨ìˆœ ì¹´ìš´íŠ¸ ë°©ì‹ + ë‚ ì”¨ ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
    
    ìœ ì €ì˜ í‚¤ì›Œë“œ + í”¼ë¶€ê³ ë¯¼ì´ ì œí’ˆ ë³¸ë¬¸ + ì œí’ˆ í‚¤ì›Œë“œì—ì„œ ëª‡ ë²ˆ ë‚˜ì˜¤ëŠ”ì§€ ì¹´ìš´íŠ¸
    
    Args:
        user_keywords: ìœ ì €ì˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (í™•ì¥ëœ ê²ƒ)
        product_content: ì œí’ˆ ë³¸ë¬¸ (products_vector.content)
        product_keywords: ì œí’ˆ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (products.keywords)
        skin_concerns: ìœ ì €ì˜ í”¼ë¶€ê³ ë¯¼ (ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ)
        weather_keywords: ë‚ ì”¨/ì‹œì¦Œ ê´€ë ¨ í‚¤ì›Œë“œ (intent=weatherì¼ ë•Œ)
        current_season: í˜„ì¬ ê³„ì ˆ (spring/summer/fall/winter)
    
    Returns:
        (score, details): 0~1 ì ìˆ˜ì™€ ìƒì„¸ ì •ë³´
    """
    # ê²€ìƒ‰í•  í‚¤ì›Œë“œ ìˆ˜ì§‘
    kws = [k.strip() for k in (user_keywords or []) if k and str(k).strip()]
    
    # í”¼ë¶€ê³ ë¯¼ ì¶”ê°€
    if skin_concerns:
        kws.extend([k.strip() for k in skin_concerns if k and str(k).strip()])
    
    # weather intentì¼ ê²½ìš° weather_keywords ì¶”ê°€
    if weather_keywords:
        kws.extend([k.strip() for k in weather_keywords if k and str(k).strip()])
    
    if not kws:
        return 0.0, {"matched_keywords": [], "hit_count": 0, "total_keywords": 0, "priority_hits": 0}

    # ê²€ìƒ‰ ëŒ€ìƒ: ì œí’ˆ ë³¸ë¬¸ + ì œí’ˆ í‚¤ì›Œë“œ í•©ì¹˜ê¸°
    search_text = (product_content or "").lower()
    if product_keywords:
        search_text += " " + " ".join([str(k).lower() for k in product_keywords])
    
    # ë„ì–´ì“°ê¸° ì œê±°í•œ ì •ê·œí™” ë²„ì „
    search_text_normalized = search_text.replace(" ", "")

    # ê³„ì ˆë³„ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
    priority_kws = []
    if current_season and current_season in WEATHER_PRIORITY_KEYWORDS:
        priority_kws = [k.lower() for k in WEATHER_PRIORITY_KEYWORDS[current_season]]

    # í‚¤ì›Œë“œ ë§¤ì¹­ ì¹´ìš´íŠ¸ (ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œëŠ” 2ë°° ê°€ì¤‘ì¹˜)
    hit_count = 0.0
    matched_keywords = []
    priority_matched = []
    
    for kw in kws:
        k = kw.lower()
        k_normalized = k.replace(" ", "")
        
        # ì›ë³¸ ë§¤ì¹­ OR ì •ê·œí™” ë§¤ì¹­
        if (k in search_text) or (k_normalized in search_text_normalized):
            matched_keywords.append(kw)
            
            # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œì¸ì§€ í™•ì¸ (ê³„ì ˆë³„ í•µì‹¬ í‚¤ì›Œë“œ)
            is_priority = any(pk in k or k in pk for pk in priority_kws)
            
            if is_priority:
                hit_count += 2.0  # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œëŠ” 2ë°° ê°€ì¤‘ì¹˜
                priority_matched.append(kw)
            else:
                hit_count += 1.0  # ì¼ë°˜ í‚¤ì›Œë“œ

    # 0~1 ì •ê·œí™” (ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœëŒ€ê°’ ì¡°ì •)
    # ëª¨ë“  í‚¤ì›Œë“œê°€ ìš°ì„ ìˆœìœ„ë¼ë©´ max = len(kws) * 2
    max_possible_score = len(kws) * 2.0 if priority_kws else len(kws)
    score = hit_count / max(max_possible_score, 1)
    
    details = {
        "matched_keywords": matched_keywords,
        "hit_count": int(hit_count),  # ì‹¤ì œ ê°€ì¤‘ì¹˜ ì ìš©ëœ ê°’
        "total_keywords": len(kws),
        "priority_hits": len(priority_matched)  # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ë§¤ì¹­ ìˆ˜
    }
    
    return float(min(1.0, max(0.0, score))), details


async def fetch_products_from_supabase() -> Dict[str, str]:
    """
    Fetch products from Supabase and format them for the LLM.
    (Deprecated - ì´ì œ recommend_product_with_brands ì‚¬ìš©)
    """
    return {}

    # url = f"{settings.SUPABASE_URL}/rest/v1/products"
    # headers = {
    #     "apikey": settings.SUPABASE_KEY,
    #     "Authorization": f"Bearer {settings.SUPABASE_KEY}",
    # }

    # try:
    #     async with httpx.AsyncClient() as http_client:
    #         response = await http_client.get(url, headers=headers)
    #         response.raise_for_status()
    #         products_data = response.json()
            
    #         # Format: "ID": "Name (Brand, Category, Description)"
    #         formatted_products = {}
    #         full_data = {}  # Store full product data
    #         for p in products_data:
    #             # Adjust field names based on actual DB schema
    #             # Schema: id, product_code, brand, name, category_major, category_middle, category_small, 
    #             # price_original, price_final, discount_rate, review_score, review_count, features, analytics, keywords
                
    #             p_id = p.get("product_code") or str(p.get("id"))
    #             name = p.get("name")
    #             brand = p.get("brand", "")
                
    #             # Construct category string
    #             cats = [p.get("category_major"), p.get("category_middle"), p.get("category_small")]
    #             category = " > ".join([c for c in cats if c])
                
    #             # Construct description from keywords and features
    #             keywords = p.get("keywords", "")
    #             price = p.get("price_final")
    #             review_score = p.get("review_score")
                
    #             desc_parts = []
    #             if keywords:
    #                 desc_parts.append(f"Keywords: {keywords}")
    #             if price:
    #                 desc_parts.append(f"Price: {price}")
    #             if review_score:
    #                 desc_parts.append(f"Rating: {review_score}")
                
    #             desc = ", ".join(desc_parts)
                
    #             if p_id and name:
    #                 info = f"{name} (Brand: {brand}, Category: {category}, {desc})"
    #                 formatted_products[p_id] = info
    #                 # Store full product data
    #                 full_data[p_id] = p
            
    #         PRODUCTS_CACHE = formatted_products
    #         PRODUCTS_FULL_DATA = full_data
            
    #         # Debug: Print first 3 products to verify format
    #         print("DEBUG: Sample products from DB:")
    #         for i, (pid, info) in enumerate(formatted_products.items()):
    #             if i >= 3: break
    #             print(f" - {pid}: {info}")
                
    #         return formatted_products
            
    # except Exception as e:
    #     print(f"Failed to fetch products from Supabase: {e}")
    #     # Fallback to empty dict or hardcoded list if needed
    #     return {}

async def recommend_product_with_brands(
    user_id: str,
    user_data: Any,
    target_brands: List[str] = None,
    top_k: int = 1,
    intent: str = ""
) -> Optional[Dict[str, Any]]:
    """
    ìœ ì € IDì™€ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ Cross-Encoder ê¸°ë°˜ìœ¼ë¡œ ìµœê³ ì˜ ìƒí’ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤.
    
    Args:
        user_id: ì‚¬ìš©ì ID
        user_data: CustomerProfile ê°ì²´ (user_dataì—ì„œ ì¶”ì¶œí•œ ì •ë³´)
        target_brands: ì¶”ì²œí•  ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ë¸Œëœë“œ)
        top_k: ë°˜í™˜í•  ìƒí’ˆ ê°œìˆ˜ (ê¸°ë³¸ê°’: 1)
        intent: ì¶”ì²œ ì˜ë„ ("": regular, "event": í• ì¸ìœ¨ ë†’ì€ ì œí’ˆ, "weather": ë‚ ì”¨ë³„ ì œí’ˆ)
        
    Returns:
        ì¶”ì²œ ìƒí’ˆ ì •ë³´ dict ë˜ëŠ” None
    """
    try:
        # Supabase ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        from supabase import create_client, Client
        sb: Client = create_client(settings.SUPABASE_URL, settings.SUPABASE_KEY)
        oa = OpenAI(api_key=settings.OPENAI_API_KEY)
        ce = get_cross_encoder()
        
        # 1) ê³ ê° ì •ë³´ ì¡°íšŒ
        customer_resp = (
            sb.table("customers")
            .select("user_id, skin_type, skin_concerns, keywords, preferred_tone")
            .eq(CUSTOMER_ID_COL, user_id)
            .limit(1)
            .execute()
        )

        print(f"customer_resp: {customer_resp}")

        
        if not customer_resp.data:
            print(f"[WARN] customersì—ì„œ {CUSTOMER_ID_COL}={user_id}ë¥¼ ì°¾ì§€ ëª»í•¨")
            return None
        
        customer = customer_resp.data[0]
        user_keywords_raw = normalize_list(customer.get("keywords"))
        
        # í‚¤ì›Œë“œ í™•ì¥: ì˜ì–´ -> í•œê¸€ ë™ì˜ì–´ ì¶”ê°€
        user_keywords = expand_keywords(user_keywords_raw)
        print(f"  ğŸ” í‚¤ì›Œë“œ í™•ì¥: {user_keywords_raw} â†’ {len(user_keywords)}ê°œ")
        
        # intent ì²˜ë¦¬: weatherì¼ ê²½ìš° ì‹œì¦Œë³„ í‚¤ì›Œë“œ ì¶”ê°€
        weather_keywords = []
        if intent == "weather":
            current_season = get_current_season()
            weather_keywords = WEATHER_KEYWORDS.get(current_season, [])
            print(f"  ğŸŒ¡ï¸ Weather Intent: {current_season} season - í‚¤ì›Œë“œ: {weather_keywords[:3]}...")
        
        # 2) ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
        query_text = build_user_query_text(customer)
        
        # 3) ì„ë² ë”© ìƒì„±
        query_emb = embed_text(oa, query_text)
        
        # 4) ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í›„ë³´ í’€)
        rpc_payload = {
            "filter": {},
            "match_count": CANDIDATE_POOL,
            "query_embedding": query_emb,
        }
        match_resp = sb.rpc("match_products", rpc_payload).execute()
        matches = match_resp.data or []
        
        if not matches:
            print("[WARN] ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        matches.sort(key=lambda m: float(m.get("similarity", 0.0)), reverse=True)
        candidate_ids = [m["product_id"] for m in matches]
        sim_map = {m["product_id"]: float(m["similarity"]) for m in matches}
        
        # 5) products ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë¸Œëœë“œ í•„í„°ë§ ì ìš©)
        query = (
            sb.table("products")
            .select("id, brand, name, category_major, category_middle, category_small, price_final, discount_rate, review_score, review_count")
            .in_("id", candidate_ids)
        )
        
        if target_brands and len(target_brands) > 0:
            query = query.in_("brand", target_brands)
            print(f"  ğŸ·ï¸ ë¸Œëœë“œ í•„í„°ë§ ì ìš©: {target_brands}")
        
        products_resp = query.execute()
        products = products_resp.data or []
        
        if not products:
            if target_brands:
                print(f"[WARN] ì§€ì •ëœ ë¸Œëœë“œ({target_brands})ì—ì„œ ìƒí’ˆì„ ì°¾ì§€ ëª»í•¨")
            else:
                print("[WARN] ìƒí’ˆì„ ì°¾ì§€ ëª»í•¨")
            return None
        
        prod_map = {p["id"]: p for p in products}
        filtered_ids = list(prod_map.keys())
        
        # 6) products_vector content ê°€ì ¸ì˜¤ê¸°
        pv_resp = (
            sb.table("products_vector")
            .select(f"{PRODUCT_VECTOR_FK_COL}, content")
            .in_(PRODUCT_VECTOR_FK_COL, filtered_ids)
            .execute()
        )
        pv_rows = pv_resp.data or []
        pv_map = {r[PRODUCT_VECTOR_FK_COL]: r.get("content") for r in pv_rows}
        
        # 7) Cross-Encoder rerank + keyword bonus
        pairs: List[Tuple[str, str]] = []
        valid_ids: List[int] = []
        
        for pid in filtered_ids:
            content = pv_map.get(pid)
            if not content:
                continue
            valid_ids.append(pid)
            pairs.append((truncate_for_ce(query_text), truncate_for_ce(content)))
        
        if not pairs:
            print("[WARN] ë¸Œëœë“œ í•„í„°ë§ í›„ products_vector.contentê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None
        
        ce_scores = ce.predict(pairs)
        
        reranked = []
        for pid, ce_score in zip(valid_ids, ce_scores):
            content = pv_map.get(pid, "")
            p = prod_map.get(pid)
            
            # ì œí’ˆ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
            product_keywords = normalize_list(p.get("keywords"))
            
            # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ ê³„ì‚° (í”¼ë¶€ê³ ë¯¼ + ë‚ ì”¨ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ í¬í•¨)
            kwb, kw_details = keyword_bonus(
                user_keywords=user_keywords,
                product_content=content,
                product_keywords=product_keywords,
                skin_concerns=concerns,
                weather_keywords=weather_keywords if intent == "weather" else None,
                current_season=current_season if intent == "weather" else None
            )
            
            final_score = float(ce_score) + KW_BONUS_ALPHA * kwb
            
            reranked.append({
                "product_id": str(pid),
                "brand": p.get("brand"),
                "name": p.get("name"),
                "category_major": p.get("category_major"),
                "category_middle": p.get("category_middle"),
                "category_small": p.get("category_small"),
                "price_final": p.get("price_final"),
                "discount_rate": p.get("discount_rate"),
                "review_score": p.get("review_score"),
                "review_count": p.get("review_count"),
                "ce_score": float(ce_score),
                "kw_bonus": float(kwb),
                "final_score": float(final_score),
                "similarity": float(sim_map.get(pid, 0.0)),
            })
        
        # intentì— ë”°ë¥¸ ì •ë ¬
        if intent == "event":
            # Event Intent: final_scoreë¡œ Top 5 ì¶”ì¶œ í›„, Top 5 ì¤‘ í• ì¸ìœ¨ ìš°ì„ 
            reranked.sort(key=lambda r: r["final_score"], reverse=True)
            if len(reranked) >= 5:
                top_5 = reranked[:5]
                top_5.sort(key=lambda r: (r.get("discount_rate") or 0), reverse=True)
                reranked = top_5 + reranked[5:]
            print(f"  ğŸ Event Intent: Top 5 ì¤‘ í• ì¸ìœ¨ ìš°ì„  (1ìœ„ í• ì¸ìœ¨: {reranked[0].get('discount_rate', 0)}%)")
        else:
            # regular ë˜ëŠ” weather: final_scoreë¡œ ì •ë ¬
            reranked.sort(key=lambda r: r["final_score"], reverse=True)
        
        # 9) ë””ë²„ê·¸ ì¶œë ¥ (ìƒìœ„ 3ê°œ)
        if reranked:
            print(f"\n  ğŸ“Š Top 3 ì¶”ì²œ ê²°ê³¼:")
            for i, r in enumerate(reranked[:3], 1):
                match_rate = kwb if i == 1 else 0.0  # 1ìœ„ë§Œ ì¶œë ¥
                print(f"    {i}. {r['name'][:30]}... (í‚¤ì›Œë“œ: {match_rate*100:.0f}%, ìµœì¢…: {r['final_score']:.3f})")
        
        # 8) top_k ê°œìˆ˜ë§Œí¼ ë°˜í™˜
        if top_k == 1:
            return reranked[0] if reranked else None
        else:
            return reranked[:top_k]
            
    except Exception as e:
        print(f"âŒ ìƒí’ˆ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


async def get_recommendation(request_data: Any) -> Dict[str, Any]:
    """
    Get recommendation using Cross-Encoder based system.
    """
    user_id = request_data.user_id
    intention = getattr(request_data, 'intention', None) or ""
    user_data = request_data.user_data
    target_brands = getattr(request_data, 'target_brand', None)
    
    print(f"\nğŸ¯ ì¶”ì²œ ìš”ì²­ ìˆ˜ì‹ :")
    print(f"  - User ID: {user_id}")
    print(f"  - Intention: {intention}")
    print(f"  - Target Brands: {target_brands}")
    
    # Cross-Encoder ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ í˜¸ì¶œ
    recommendation = await recommend_product_with_brands(
        user_id=user_id,
        user_data=user_data,
        target_brands=target_brands if target_brands else [],
        top_k=1,
        intent=intention
    )
    
    if recommendation:
        print(f"  âœ… ìƒí’ˆ ì¶”ì²œ ì„±ê³µ: {recommendation['name']} (ID: {recommendation['product_id']})")
        print(f"  ğŸ“Š Score: ce={recommendation['ce_score']:.4f}, kw_bonus={recommendation['kw_bonus']:.3f}, final={recommendation['final_score']:.4f}")
        
        result = {
            "product_id": recommendation['product_id'],
            "product_name": recommendation['name'],
            "score": recommendation['final_score'],
            "reason": f"Cross-Encoder ì ìˆ˜: {recommendation['ce_score']:.4f}, í‚¤ì›Œë“œ ë§¤ì¹­: {recommendation['kw_bonus']:.3f}",
            "product_data": {
                "product_id": recommendation['product_id'],
                "brand": recommendation['brand'],
                "name": recommendation['name'],
                "category": {
                    "major": recommendation['category_major'],
                    "middle": recommendation['category_middle'],
                    "small": recommendation['category_small'],
                },
                "price": {
                    "original_price": recommendation['price_final'],
                    "discounted_price": recommendation['price_final'],
                    "discount_rate": recommendation['discount_rate'],
                },
                "review": {
                    "score": recommendation['review_score'],
                    "count": recommendation['review_count'],
                    "top_keywords": [],
                },
                "description_short": f"{recommendation['name']} - {recommendation['brand']}",
            }
        }
        return result
    
    # ì¶”ì²œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
    print("  âš ï¸ ì¶”ì²œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜")
    return {
        "product_id": "UNKNOWN",
        "product_name": "ì¶”ì²œ ì‹¤íŒ¨",
        "score": 0.0,
        "reason": "ìƒí’ˆ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
    }


